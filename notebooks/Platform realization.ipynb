{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tempfile\n",
    "import pathlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:52:16.436714Z",
     "end_time": "2023-07-06T11:52:16.455872Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Platform class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Platform:\n",
    "    def __init__(self, algorithm, processing, table_path):\n",
    "        self.algorithm = algorithm\n",
    "        self.processing = processing\n",
    "        self.table_path = table_path\n",
    "        self.logs = False\n",
    "\n",
    "\n",
    "        self.benchmark = {\"name\" : type(self.algorithm).__name__, \"table_path\": table_path}\n",
    "\n",
    "    def start(self, run_type=\"test\", logs=False):\n",
    "        self.logs = logs\n",
    "\n",
    "        if self.logs:\n",
    "            if isinstance(self.algorithm, LosslessCompressionAlgorithm):\n",
    "                self.benchmark[\"isLossLess\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLossLess\"] = False\n",
    "\n",
    "            if isinstance(self.algorithm, LearningCompressionAlgorithm):\n",
    "                self.benchmark[\"isLearning\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLearning\"] = False\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmp:\n",
    "            if run_type == 'test':\n",
    "                self.test()\n",
    "            elif run_type == 'compress':\n",
    "                self.preprocess_and_compress()\n",
    "            elif run_type == 'decompress':\n",
    "                self.decompress_and_postprocess()\n",
    "\n",
    "    def measure_time(flag):\n",
    "        def decorator(func):\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                start_time = time.time()\n",
    "                result = func(self, *args, **kwargs)\n",
    "                end_time = time.time()\n",
    "\n",
    "                if getattr(self, flag):\n",
    "                    print(f\"Function {func.__name__} took {end_time - start_time} seconds to execute.\")\n",
    "                    self.benchmark[func.__name__ + \"_time\"] = end_time - start_time\n",
    "\n",
    "                return result\n",
    "            return wrapper\n",
    "        return decorator\n",
    "\n",
    "    def get_names(self):\n",
    "        return {\"compressed\": self.table_path + \"_compressed\",\n",
    "                 \"decompressed\": self.table_path + \"_decompressed\",\n",
    "                 \"preprocessed\": self.table_path + \"_preprocessed\"}\n",
    "\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def preprocess_and_compress(self):\n",
    "        names = self.get_names()\n",
    "        with open(self.table_path, 'a+b') as table_file, open(names[\"compressed\"], 'wb') as compressed_file, open(names[\"preprocessed\"], 'w+b') as preprocessed_file:\n",
    "            self.processing.do_preprocess(table_file, preprocessed_file)\n",
    "            self.algorithm.compress(preprocessed_file, compressed_file)\n",
    "            if self.logs:\n",
    "                compression_rate = self.get_compression_rate(table_file, compressed_file)\n",
    "                self.benchmark[\"compression_rate\"] = compression_rate\n",
    "        return 0\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def decompress_and_postprocess(self):\n",
    "        names = self.get_names()\n",
    "        with open(names[\"compressed\"], 'a+b') as compressed_file, open(names[\"decompressed\"], 'wb') as decompressed_file, open(self.table_path, 'rb') as profile_file:\n",
    "            self.algorithm.decompress(compressed_file, decompressed_file)\n",
    "            self.processing.do_postprocess(decompressed_file)\n",
    "\n",
    "            if self.logs and profile_file is not None:\n",
    "                loss_rate = self.get_loss_rate(profile_file, decompressed_file)\n",
    "                self.benchmark[\"loss_rate\"] = loss_rate\n",
    "\n",
    "        return 0\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def test(self):\n",
    "        self.preprocess_and_compress()\n",
    "        self.decompress_and_postprocess()\n",
    "        return 0 #TODO: result codes\n",
    "\n",
    "    def get_compression_rate(self, input_file, compressed_file): #I'm assuming compressed_table is actually bytes-like\n",
    "\n",
    "        print(compressed_file.name)\n",
    "        input_file.seek(0, os.SEEK_END)\n",
    "        compressed_file.seek(0, os.SEEK_END)\n",
    "        print(input_file.tell())\n",
    "        print(compressed_file.tell())\n",
    "        return input_file.tell() / compressed_file.tell()\n",
    "\n",
    "    def get_loss_rate(self, input_file, decompressed_file):\n",
    "        print(\"I am dummy: \", inspect.currentframe().f_code.co_name)\n",
    "        return random.randint(0, 20)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:59:06.829900Z",
     "end_time": "2023-07-06T11:59:06.833659Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0009961128234863281 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0012292861938477 seconds to execute.\n",
      "Function test took 1.002225399017334 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "def json_platform(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    platform = Platform(globals()[config[\"Algorithm\"]](), globals()[config[\"Processing\"]](), config[\"table_path\"])\n",
    "    platform.start(config[\"run_type\"], config[\"logs\"])\n",
    "\n",
    "json_platform(\"plug_config.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:59:59.052509Z",
     "end_time": "2023-07-06T12:00:00.057223Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compression Algorithm Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class CompressionAlgorithm(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        ...\n",
    "\n",
    "class LearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, training_data):\n",
    "        ...\n",
    "\n",
    "class NonLearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "class LosslessCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "class LossyCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:25:40.550125Z",
     "end_time": "2023-07-06T11:25:40.555146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [],
   "source": [
    "class DummyCompressionAlgorithm(LosslessCompressionAlgorithm, NonLearningCompressionAlgorithm):\n",
    "    name = 'Dummy Compression Algorithm'\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        table_file.seek(0)\n",
    "        compressed_file.seek(0)\n",
    "        compressed_file.write(table_file.read())\n",
    "        print(table_file.read())\n",
    "        print(\"I am dummy compression\")\n",
    "        return 0 # TODO: status codes\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        compressed_file.seek(0)\n",
    "        decompressed_file.seek(0)\n",
    "        decompressed_file.write(compressed_file.read())\n",
    "        time.sleep(1)\n",
    "        print(\"I am dummy decompression\")\n",
    "        return 0 # TODO: status codes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:57:31.754621Z",
     "end_time": "2023-07-06T11:57:31.760607Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processing Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "class Processing(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_preprocess(self, raw_file, processed_file):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_postprocess(self, processed_file):\n",
    "        ..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:25:41.669453Z",
     "end_time": "2023-07-06T11:25:41.670459Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "class DummyProcessing(Processing):\n",
    "    name = \"Dummy Pre/Post-Processing\"\n",
    "    def do_preprocess(self, raw_file, processed_file):\n",
    "        raw_file.seek(0)\n",
    "        processed_file.seek(0)\n",
    "        processed_file.write(raw_file.read())\n",
    "        return 0 # TODO: replace with enum / status codes\n",
    "    def do_postprocess(self, processed_file):\n",
    "        return 0 # TODO: replace with enum/status codes\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T11:56:50.305426Z",
     "end_time": "2023-07-06T11:56:50.307074Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0009963512420654297 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0013847351074219 seconds to execute.\n",
      "Function test took 1.0023810863494873 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0009963512420654297, 'loss_rate': 8, 'decompress_and_postprocess_time': 1.0013847351074219, 'test_time': 1.0023810863494873}\n",
      "---------------------\n",
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0009970664978027344 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.002249002456665 seconds to execute.\n",
      "Function test took 1.0032460689544678 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0009970664978027344, 'loss_rate': 9, 'decompress_and_postprocess_time': 1.002249002456665, 'test_time': 1.0032460689544678}\n",
      "---------------------\n",
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0010006427764892578 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0006129741668701 seconds to execute.\n",
      "Function test took 1.0016136169433594 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0010006427764892578, 'loss_rate': 11, 'decompress_and_postprocess_time': 1.0006129741668701, 'test_time': 1.0016136169433594}\n",
      "---------------------\n",
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0009963512420654297 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0028557777404785 seconds to execute.\n",
      "Function test took 1.003852128982544 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0009963512420654297, 'loss_rate': 18, 'decompress_and_postprocess_time': 1.0028557777404785, 'test_time': 1.003852128982544}\n",
      "---------------------\n",
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0009961128234863281 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.00136137008667 seconds to execute.\n",
      "Function test took 1.0023574829101562 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0009961128234863281, 'loss_rate': 8, 'decompress_and_postprocess_time': 1.00136137008667, 'test_time': 1.0023574829101562}\n",
      "---------------------\n",
      "b''\n",
      "I am dummy compression\n",
      "flush.txt_compressed\n",
      "12\n",
      "12\n",
      "Function preprocess_and_compress took 0.0 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0014004707336426 seconds to execute.\n",
      "Function test took 1.0014004707336426 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 0.0, 'loss_rate': 5, 'decompress_and_postprocess_time': 1.0014004707336426, 'test_time': 1.0014004707336426}\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "Algos = [DummyCompressionAlgorithm(), DummyCompressionAlgorithm(), DummyCompressionAlgorithm()]\n",
    "Processes = [DummyProcessing(), DummyProcessing()]\n",
    "for algo in Algos:\n",
    "    for proc in Processes:\n",
    "        a = Platform(algo, proc, \"flush.txt\")\n",
    "        a.start(\"test\", logs=True)\n",
    "        print(a.benchmark)\n",
    "        benchmarks.append(a.benchmark)\n",
    "        print(\"---------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T12:00:20.162620Z",
     "end_time": "2023-07-06T12:00:26.185107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#1. replace json with arguments of the class | DONE\n",
    "#2. do not keep table in class instance | DONE\n",
    "#3. change names of the Platform to more relevant | DONE\n",
    "#4. rename compression to compress | DONE\n",
    "#5. add ability to not compress tables every time Platform being created | I can just pass already preprocessed table to Platform\n",
    "#and also pass the flush preprocessing class which do nothing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.111686Z",
     "end_time": "2023-07-05T20:45:59.114707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphics(n_values):\n",
    "    plt.bar(range(len(n_values)), n_values)\n",
    "    plt.title('Comparison of n Values')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.117698Z",
     "end_time": "2023-07-05T20:45:59.121953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_benchmarks(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.barplot(x='index', y=column_name, data=df)\n",
    "\n",
    "def plot_scatter(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.scatterplot(x='index', y=column_name, data=df)\n",
    "\n",
    "def plot_hist(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.histplot(x='index', y=column_name, data=df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.125942Z",
     "end_time": "2023-07-05T20:45:59.127912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_benchmarks(benchmarks, \"loss_rate\")\n",
    "for i in benchmarks:\n",
    "    print(i[\"loss_rate\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.129907Z",
     "end_time": "2023-07-05T20:45:59.259271Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_scatter(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.261269Z",
     "end_time": "2023-07-05T20:45:59.419255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_hist(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T20:45:59.420251Z",
     "end_time": "2023-07-05T20:45:59.586424Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
