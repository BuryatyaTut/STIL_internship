{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "import pathlib\n",
    "import zstandard as zstd\n",
    "import abc\n",
    "import brotli\n",
    "import zlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Platform class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Platform:\n",
    "    def __init__(self, algorithm, processing, table_path):\n",
    "        self.algorithm = algorithm\n",
    "        self.processing = processing\n",
    "        self.table_path = table_path\n",
    "        self.logs = False\n",
    "\n",
    "        self.benchmark = {\"name\": type(self.algorithm).__name__, \"table_path\": table_path}\n",
    "\n",
    "    def start(self, run_type=\"test\", logs=False):\n",
    "        self.logs = logs\n",
    "\n",
    "        if self.logs:\n",
    "            if isinstance(self.algorithm, LosslessCompressionAlgorithm):\n",
    "                self.benchmark[\"isLossLess\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLossLess\"] = False\n",
    "\n",
    "            if isinstance(self.algorithm, LearningCompressionAlgorithm):\n",
    "                self.benchmark[\"isLearning\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLearning\"] = False\n",
    "\n",
    "        if run_type == 'test':\n",
    "            self.test()\n",
    "        elif run_type == 'compress':\n",
    "            self.preprocess_and_compress()\n",
    "        elif run_type == 'decompress':\n",
    "            self.decompress_and_postprocess()\n",
    "\n",
    "    def measure_time(flag):\n",
    "        def decorator(func):\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                start_time = time.time()\n",
    "                result = func(self, *args, **kwargs)\n",
    "                end_time = time.time()\n",
    "\n",
    "                if getattr(self, flag):\n",
    "                    print(f\"Function {func.__name__} took {end_time - start_time} seconds to execute.\")\n",
    "                    self.benchmark[func.__name__ + \"_time\"] = end_time - start_time\n",
    "\n",
    "                return result\n",
    "\n",
    "            return wrapper\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    def get_names(self):\n",
    "        return {\"compressed\": self.table_path + \"_compressed\",\n",
    "                \"decompressed\": self.table_path + \"_decompressed\",\n",
    "                \"preprocessed\": self.table_path + \"_preprocessed\"}\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def preprocess_and_compress(self):\n",
    "        names = self.get_names()\n",
    "\n",
    "        table_file = open(self.table_path, 'rb')\n",
    "        preprocessed_file = open(names[\"preprocessed\"], 'w+b')\n",
    "        self.processing.do_preprocess(table_file, preprocessed_file)\n",
    "        table_file.close()\n",
    "\n",
    "        compressed_file = open(names[\"compressed\"], 'wb')\n",
    "        self.algorithm.compress(preprocessed_file, compressed_file)\n",
    "        preprocessed_file.close()\n",
    "\n",
    "        if self.logs:\n",
    "            table_file = open(self.table_path, 'rb')\n",
    "\n",
    "            compression_rate = self.get_compression_rate(table_file, compressed_file)\n",
    "\n",
    "            compressed_file.close()\n",
    "            table_file.close()\n",
    "\n",
    "            self.benchmark[\"compression_rate\"] = compression_rate\n",
    "        return 0\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def decompress_and_postprocess(self):\n",
    "        names = self.get_names()\n",
    "\n",
    "        compressed_file = open(names[\"compressed\"], 'a+b')\n",
    "        decompressed_file = open(names['decompressed'], 'wb')\n",
    "\n",
    "        self.algorithm.decompress(compressed_file, decompressed_file)\n",
    "        compressed_file.close()\n",
    "\n",
    "        self.processing.do_postprocess(decompressed_file)\n",
    "\n",
    "        if self.logs:\n",
    "            profile_file = open(self.table_path, 'rb')\n",
    "            loss_rate = self.get_loss_rate(profile_file, decompressed_file)\n",
    "            profile_file.close()\n",
    "            self.benchmark[\"loss_rate\"] = loss_rate\n",
    "\n",
    "        return 0\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def test(self):\n",
    "        self.preprocess_and_compress()\n",
    "        self.decompress_and_postprocess()\n",
    "        return 0  #TODO: result codes\n",
    "\n",
    "    def get_compression_rate(self, input_file, compressed_file):  #I'm assuming compressed_table is actually bytes-like\n",
    "        input_file.seek(0, os.SEEK_END)\n",
    "        compressed_file.seek(0, os.SEEK_END)\n",
    "        print(compressed_file.name, input_file.tell(), compressed_file.tell())\n",
    "        return compressed_file.tell() / input_file.tell()\n",
    "\n",
    "    def get_loss_rate(self, input_file, decompressed_file):\n",
    "        print(\"I am dummy: \", inspect.currentframe().f_code.co_name)\n",
    "        return random.randint(0, 20)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "I am dummy compression\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 9\u001B[0m\n\u001B[0;32m      5\u001B[0m     platform \u001B[38;5;241m=\u001B[39m Platform(\u001B[38;5;28mglobals\u001B[39m()[config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAlgorithm\u001B[39m\u001B[38;5;124m\"\u001B[39m]](), \u001B[38;5;28mglobals\u001B[39m()[config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing\u001B[39m\u001B[38;5;124m\"\u001B[39m]](), config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtable_path\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m      6\u001B[0m     platform\u001B[38;5;241m.\u001B[39mstart(config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_type\u001B[39m\u001B[38;5;124m\"\u001B[39m], config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m----> 9\u001B[0m \u001B[43mjson_platform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mplug_config.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[27], line 6\u001B[0m, in \u001B[0;36mjson_platform\u001B[1;34m(config_path)\u001B[0m\n\u001B[0;32m      3\u001B[0m     config \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[0;32m      5\u001B[0m platform \u001B[38;5;241m=\u001B[39m Platform(\u001B[38;5;28mglobals\u001B[39m()[config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAlgorithm\u001B[39m\u001B[38;5;124m\"\u001B[39m]](), \u001B[38;5;28mglobals\u001B[39m()[config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing\u001B[39m\u001B[38;5;124m\"\u001B[39m]](), config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtable_path\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m----> 6\u001B[0m \u001B[43mplatform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[26], line 25\u001B[0m, in \u001B[0;36mPlatform.start\u001B[1;34m(self, run_type, logs)\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbenchmark[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124misLearning\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 25\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m run_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompress\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_and_compress()\n",
      "Cell \u001B[1;32mIn[26], line 35\u001B[0m, in \u001B[0;36mPlatform.measure_time.<locals>.decorator.<locals>.wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     34\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 35\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     36\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, flag):\n",
      "Cell \u001B[1;32mIn[26], line 99\u001B[0m, in \u001B[0;36mPlatform.test\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;129m@measure_time\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtest\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess_and_compress\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecompress_and_postprocess()\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n",
      "Cell \u001B[1;32mIn[26], line 35\u001B[0m, in \u001B[0;36mPlatform.measure_time.<locals>.decorator.<locals>.wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     34\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 35\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     36\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, flag):\n",
      "Cell \u001B[1;32mIn[26], line 69\u001B[0m, in \u001B[0;36mPlatform.preprocess_and_compress\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogs:\n\u001B[0;32m     67\u001B[0m     table_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtable_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 69\u001B[0m     compression_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_compression_rate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompressed_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m     compressed_file\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     72\u001B[0m     table_file\u001B[38;5;241m.\u001B[39mclose()\n",
      "Cell \u001B[1;32mIn[26], line 106\u001B[0m, in \u001B[0;36mPlatform.get_compression_rate\u001B[1;34m(self, input_file, compressed_file)\u001B[0m\n\u001B[0;32m    104\u001B[0m input_file\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m, os\u001B[38;5;241m.\u001B[39mSEEK_END)\n\u001B[0;32m    105\u001B[0m compressed_file\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m, os\u001B[38;5;241m.\u001B[39mSEEK_END)\n\u001B[1;32m--> 106\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcompressed_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minput_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtell\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m compressed_file\u001B[38;5;241m.\u001B[39mtell())\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m compressed_file\u001B[38;5;241m.\u001B[39mtell() \u001B[38;5;241m/\u001B[39m input_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "\u001B[1;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "def json_platform(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    platform = Platform(globals()[config[\"Algorithm\"]](), globals()[config[\"Processing\"]](), config[\"table_path\"])\n",
    "    platform.start(config[\"run_type\"], config[\"logs\"])\n",
    "\n",
    "\n",
    "json_platform(\"plug_config.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compression Algorithm Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "\n",
    "class CompressionAlgorithm(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        ...\n",
    "\n",
    "\n",
    "class LearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, training_data):\n",
    "        ...\n",
    "\n",
    "\n",
    "class NonLearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "\n",
    "class LosslessCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "\n",
    "class LossyCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class DummyCompressionAlgorithm(LosslessCompressionAlgorithm, NonLearningCompressionAlgorithm):\n",
    "    name = 'Dummy Compression Algorithm'\n",
    "\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        table_file.seek(0)\n",
    "        compressed_file.seek(0)\n",
    "        compressed_file.write(table_file.read())\n",
    "        print(table_file.read())\n",
    "        print(\"I am dummy compression\")\n",
    "        return 0  # TODO: status codes\n",
    "\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        compressed_file.seek(0)\n",
    "        decompressed_file.seek(0)\n",
    "        decompressed_file.write(compressed_file.read())\n",
    "        time.sleep(1)\n",
    "        print(\"I am dummy decompression\")\n",
    "        return 0  # TODO: status codes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class ZstdLibraryCompressionAlgorithm(LosslessCompressionAlgorithm, NonLearningCompressionAlgorithm):\n",
    "    name = 'zstd library'\n",
    "\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        table_file.seek(0)\n",
    "        compressed_file.seek(0)\n",
    "        compressor = zstd.ZstdCompressor(level=22)\n",
    "        compressor.copy_stream(table_file, compressed_file)\n",
    "        return 0\n",
    "\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        compressed_file.seek(0)\n",
    "        decompressed_file.seek(0)\n",
    "        decompressor = zstd.ZstdDecompressor()\n",
    "        decompressor.copy_stream(compressed_file, decompressed_file)\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class BrotliLibraryCompressionAlgorithm(LosslessCompressionAlgorithm, NonLearningCompressionAlgorithm):\n",
    "    name = 'brotli library'\n",
    "\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        table_file.seek(0)\n",
    "        compressed_file.seek(0)\n",
    "        compressed_file.write(brotli.compress(table_file.read()))\n",
    "        return 0\n",
    "\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        compressed_file.seek(0)\n",
    "        decompressed_file.seek(0)\n",
    "        decompressed_file.write(brotli.decompress(compressed_file.read()))\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class ZlibCompression(NonLearningCompressionAlgorithm, LosslessCompressionAlgorithm):\n",
    "    name = 'zlib'\n",
    "\n",
    "    def compress(self, table_file, compressed_file):\n",
    "        table_file.seek(0)\n",
    "        compressed_file.seek(0)\n",
    "\n",
    "        data = table_file.read()\n",
    "        compressed_data = zlib.compress(data)\n",
    "        compressed_file.write(compressed_data)\n",
    "\n",
    "    def decompress(self, compressed_file, decompressed_file):\n",
    "        compressed_file.seek(0)\n",
    "        decompressed_file.seek(0)\n",
    "\n",
    "        data = compressed_file.read()\n",
    "        decompressed_data = zlib.decompress(data)\n",
    "        decompressed_file.write(decompressed_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processing Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class Processing(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_preprocess(self, raw_file, processed_file):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_postprocess(self, processed_file):\n",
    "        ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class DummyProcessing(Processing):\n",
    "    name = \"Dummy Pre/Post-Processing\"\n",
    "\n",
    "    def do_preprocess(self, raw_file, processed_file):\n",
    "        raw_file.seek(0)\n",
    "        processed_file.seek(0)\n",
    "        processed_file.write(raw_file.read())\n",
    "        return 0  # TODO: replace with enum / status codes\n",
    "\n",
    "    def do_postprocess(self, processed_file):\n",
    "        return 0  # TODO: replace with enum/status codes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "I am dummy compression\n",
      "data/sample_dataset.csv_compressed 178773868 178773868\n",
      "Function preprocess_and_compress took 1.446197748184204 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.4190223217010498 seconds to execute.\n",
      "Function test took 2.865220069885254 seconds to execute.\n",
      "{'name': 'DummyCompressionAlgorithm', 'table_path': 'data/sample_dataset.csv', 'isLossLess': True, 'isLearning': False, 'compression_rate': 1.0, 'preprocess_and_compress_time': 1.446197748184204, 'loss_rate': 5, 'decompress_and_postprocess_time': 1.4190223217010498, 'test_time': 2.865220069885254}\n",
      "---------------------\n",
      "data/sample_dataset.csv_compressed 178773868 64455677\n",
      "Function preprocess_and_compress took 11.156059980392456 seconds to execute.\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0556626319885254 seconds to execute.\n",
      "Function test took 12.211722612380981 seconds to execute.\n",
      "{'name': 'ZlibCompression', 'table_path': 'data/sample_dataset.csv', 'isLossLess': True, 'isLearning': False, 'compression_rate': 0.36054305766880873, 'preprocess_and_compress_time': 11.156059980392456, 'loss_rate': 0, 'decompress_and_postprocess_time': 1.0556626319885254, 'test_time': 12.211722612380981}\n",
      "---------------------\n",
      "data/sample_dataset.csv_compressed 178773868 50063940\n",
      "Function preprocess_and_compress took 248.04562067985535 seconds to execute.\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 0.4230489730834961 seconds to execute.\n",
      "Function test took 248.46866965293884 seconds to execute.\n",
      "{'name': 'ZstdLibraryCompressionAlgorithm', 'table_path': 'data/sample_dataset.csv', 'isLossLess': True, 'isLearning': False, 'compression_rate': 0.2800405929573555, 'preprocess_and_compress_time': 248.04562067985535, 'loss_rate': 2, 'decompress_and_postprocess_time': 0.4230489730834961, 'test_time': 248.46866965293884}\n",
      "---------------------\n",
      "data/sample_dataset.csv_compressed 178773868 48506544\n",
      "Function preprocess_and_compress took 333.7031464576721 seconds to execute.\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.3379919528961182 seconds to execute.\n",
      "Function test took 335.04113841056824 seconds to execute.\n",
      "{'name': 'BrotliLibraryCompressionAlgorithm', 'table_path': 'data/sample_dataset.csv', 'isLossLess': True, 'isLearning': False, 'compression_rate': 0.2713290512906506, 'preprocess_and_compress_time': 333.7031464576721, 'loss_rate': 6, 'decompress_and_postprocess_time': 1.3379919528961182, 'test_time': 335.04113841056824}\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "Algos = [DummyCompressionAlgorithm(), ZlibCompression(), ZstdLibraryCompressionAlgorithm(), BrotliLibraryCompressionAlgorithm()]\n",
    "Processes = [DummyProcessing()]\n",
    "for algo in Algos:\n",
    "    for proc in Processes:\n",
    "        a = Platform(algo, proc, \"data/sample_dataset.csv\")\n",
    "        a.start(\"test\", logs=True)\n",
    "        print(a.benchmark)\n",
    "        benchmarks.append(a.benchmark)\n",
    "        print(\"---------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#1. replace json with arguments of the class | DONE\n",
    "#2. do not keep table in class instance | DONE\n",
    "#3. change names of the Platform to more relevant | DONE\n",
    "#4. rename compression to compress | DONE\n",
    "#5. add ability to not compress tables every time Platform being created | I can just pass already preprocessed table to Platform\n",
    "#and also pass the flush preprocessing class which do nothing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphics(n_values):\n",
    "    plt.bar(range(len(n_values)), n_values)\n",
    "    plt.title('Comparison of n Values')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_benchmarks(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.barplot(x='index', y=column_name, data=df)\n",
    "\n",
    "\n",
    "def plot_scatter(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.scatterplot(x='index', y=column_name, data=df)\n",
    "\n",
    "\n",
    "def plot_hist(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.histplot(x='index', y=column_name, data=df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_benchmarks(benchmarks, \"compression_rate\")\n",
    "for i in benchmarks:\n",
    "    print(i[\"loss_rate\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_scatter(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_hist(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}