{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T16:56:39.748196Z",
     "end_time": "2023-07-05T16:56:39.752194Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Platform class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "class Platform:\n",
    "    def __init__(self, algorithm, processing, table_path):\n",
    "        self.algorithm = algorithm\n",
    "        self.processing = processing\n",
    "        self.table_path = table_path\n",
    "        self.logs = False\n",
    "\n",
    "        self.benchmark = {\"name\" : type(self.algorithm).__name__, \"table_path\": table_path}\n",
    "\n",
    "    def start(self, run_type=\"test\", logs=False):\n",
    "        self.logs = logs\n",
    "\n",
    "        if self.logs:\n",
    "            if isinstance(self.algorithm, LosslessCompressionAlgorithm):\n",
    "                self.benchmark[\"isLossLess\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLossLess\"] = False\n",
    "\n",
    "            if isinstance(self.algorithm, LearningCompressionAlgorithm):\n",
    "                self.benchmark[\"isLearning\"] = True\n",
    "            else:\n",
    "                self.benchmark[\"isLearning\"] = False\n",
    "\n",
    "\n",
    "        if run_type == 'test':\n",
    "            self.test()\n",
    "        elif run_type == 'compress':\n",
    "            self.preprocess_and_compress()\n",
    "        elif run_type == 'decompress':\n",
    "            self.decompress_and_postprocess()\n",
    "\n",
    "    def measure_time(flag):\n",
    "        def decorator(func):\n",
    "            def wrapper(self, *args, **kwargs):\n",
    "                start_time = time.time()\n",
    "                result = func(self, *args, **kwargs)\n",
    "                end_time = time.time()\n",
    "\n",
    "                if getattr(self, flag):\n",
    "                    print(f\"Function {func.__name__} took {end_time - start_time} seconds to execute.\")\n",
    "                    self.benchmark[func.__name__ + \"_time\"] = end_time - start_time\n",
    "\n",
    "                return result\n",
    "            return wrapper\n",
    "        return decorator\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def preprocess_and_compress(self):\n",
    "        preprocessed_table = self.processing.do_preprocess(self.table_path)\n",
    "        compressed_table = self.algorithm.compress(self.table_path)\n",
    "        if self.logs:\n",
    "            compression_rate = self.get_compression_rate(compressed_table)\n",
    "            self.benchmark[\"compression_rate\"] = compression_rate\n",
    "        return compressed_table\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def decompress_and_postprocess(self, compressed_table):\n",
    "        decompressed_table = self.algorithm.decompress(compressed_table)\n",
    "        table = self.processing.do_postprocess(decompressed_table)\n",
    "\n",
    "        if self.logs:\n",
    "            loss_rate = self.get_loss_rate(table)\n",
    "            self.benchmark[\"loss_rate\"] = loss_rate\n",
    "\n",
    "        return table\n",
    "\n",
    "    @measure_time(\"logs\")\n",
    "    def test(self):\n",
    "        compressed_data = self.preprocess_and_compress()\n",
    "        decompressed_data = self.decompress_and_postprocess(compressed_data)\n",
    "\n",
    "    def get_compression_rate(self, compressed_table): #I'm assuming compressed_table is actually bytes-like\n",
    "        print(compressed_table)\n",
    "        with open(self.table_path, 'rb') as f:\n",
    "            f.seek(0, os.SEEK_END)\n",
    "            return f.tell() / len(compressed_table)\n",
    "\n",
    "    def get_loss_rate(self, table):\n",
    "        print(\"I am dummy: \", inspect.currentframe().f_code.co_name)\n",
    "        return random.randint(0, 20)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T19:16:11.037643Z",
     "end_time": "2023-07-05T19:16:11.042052Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am dummy compression\n",
      "plug_config.json\n",
      "Function preprocess_and_compress took 2.0007336139678955 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0007081031799316 seconds to execute.\n",
      "Function test took 3.001441717147827 seconds to execute.\n"
     ]
    }
   ],
   "source": [
    "def json_platform(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    platform = Platform(globals()[config[\"Algorithm\"]](), globals()[config[\"Processing\"]](), config[\"table_path\"])\n",
    "    platform.start(config[\"run_type\"], config[\"logs\"])\n",
    "\n",
    "json_platform(\"plug_config.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:41.420855Z",
     "end_time": "2023-07-05T19:15:44.426751Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compression Algorithm Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class CompressionAlgorithm(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def compress(self, table):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def decompress(self, compressed_data):\n",
    "        ...\n",
    "\n",
    "class LearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, training_data):\n",
    "        ...\n",
    "\n",
    "class NonLearningCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "class LosslessCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ...\n",
    "\n",
    "class LossyCompressionAlgorithm(CompressionAlgorithm):\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:44.431164Z",
     "end_time": "2023-07-05T19:15:44.432667Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "class DummyCompressionAlgorithm(LosslessCompressionAlgorithm, LearningCompressionAlgorithm):\n",
    "    name = 'Dummy Compression Algorithm'\n",
    "    def compress(self, table):\n",
    "        time.sleep(2)\n",
    "        print(\"I am dummy compression\")\n",
    "        return table\n",
    "    def decompress(self, compressed_data):\n",
    "        time.sleep(1)\n",
    "        print(\"I am dummy decompression\")\n",
    "        return compressed_data\n",
    "\n",
    "    def fit(self, training_data):\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:44.435663Z",
     "end_time": "2023-07-05T19:15:44.438820Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processing Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "class Processing(abc.ABC):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def name(self):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_preprocess(self, raw_table):\n",
    "        ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def do_postprocess(self, processed_table):\n",
    "        ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:44.441812Z",
     "end_time": "2023-07-05T19:15:44.444917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "class DummyProcessing(Processing):\n",
    "    name = \"Dummy Pre/Post-Processing\"\n",
    "    def do_preprocess(self, raw_table):\n",
    "        return raw_table\n",
    "    def do_postprocess(self, processed_table):\n",
    "        return processed_table\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:44.447911Z",
     "end_time": "2023-07-05T19:15:44.450411Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.0009756088256836 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0008049011230469 seconds to execute.\n",
      "Function test took 3.0017805099487305 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.0009756088256836, 'loss_rate': 1, 'decompress_and_postprocess_time': 1.0008049011230469, 'test_time': 3.0017805099487305}\n",
      "---------------------\n",
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.0004706382751465 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0008533000946045 seconds to execute.\n",
      "Function test took 3.001323938369751 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.0004706382751465, 'loss_rate': 4, 'decompress_and_postprocess_time': 1.0008533000946045, 'test_time': 3.001323938369751}\n",
      "---------------------\n",
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.0007143020629883 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0007436275482178 seconds to execute.\n",
      "Function test took 3.001457929611206 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.0007143020629883, 'loss_rate': 8, 'decompress_and_postprocess_time': 1.0007436275482178, 'test_time': 3.001457929611206}\n",
      "---------------------\n",
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.0005526542663574 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.000697374343872 seconds to execute.\n",
      "Function test took 3.0012500286102295 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.0005526542663574, 'loss_rate': 6, 'decompress_and_postprocess_time': 1.000697374343872, 'test_time': 3.0012500286102295}\n",
      "---------------------\n",
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.0004308223724365 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.0006747245788574 seconds to execute.\n",
      "Function test took 3.001105546951294 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.0004308223724365, 'loss_rate': 15, 'decompress_and_postprocess_time': 1.0006747245788574, 'test_time': 3.001105546951294}\n",
      "---------------------\n",
      "I am dummy compression\n",
      "flush.txt\n",
      "Function preprocess_and_compress took 2.000951051712036 seconds to execute.\n",
      "I am dummy decompression\n",
      "I am dummy:  get_loss_rate\n",
      "Function decompress_and_postprocess took 1.000715732574463 seconds to execute.\n",
      "Function test took 3.001666784286499 seconds to execute.\n",
      "{'table_path': 'flush.txt', 'isLossLess': True, 'isLearning': True, 'compression_rate': 0.2222222222222222, 'preprocess_and_compress_time': 2.000951051712036, 'loss_rate': 8, 'decompress_and_postprocess_time': 1.000715732574463, 'test_time': 3.001666784286499}\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "benchmarks = []\n",
    "Algos = [DummyCompressionAlgorithm(), DummyCompressionAlgorithm(), DummyCompressionAlgorithm()]\n",
    "Processes = [DummyProcessing(), DummyProcessing()]\n",
    "for algo in Algos:\n",
    "    for proc in Processes:\n",
    "        a = Platform(algo, proc, \"flush.txt\")\n",
    "        a.start(\"test\", logs=True)\n",
    "        print(a.benchmark)\n",
    "        benchmarks.append(a.benchmark)\n",
    "        print(\"---------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T19:15:44.453403Z",
     "end_time": "2023-07-05T19:16:02.464814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "#1. replace json with arguments of the class | DONE\n",
    "#2. do not keep table in class instance | DONE\n",
    "#3. change names of the Platform to more relevant | DONE\n",
    "#4. rename compression to compress | DONE\n",
    "#5. add ability to not compress tables every time Platform being created | I can just pass already preprocessed table to Platform\n",
    "#and also pass the flush preprocessing class which do nothing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T19:16:02.467678Z",
     "end_time": "2023-07-05T19:16:02.468684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphics(n_values):\n",
    "    plt.bar(range(len(n_values)), n_values)\n",
    "    plt.title('Comparison of n Values')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_benchmarks(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.barplot(x='index', y=column_name, data=df)\n",
    "\n",
    "def plot_scatter(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.scatterplot(x='index', y=column_name, data=df)\n",
    "\n",
    "def plot_hist(benchmarks, column_name):\n",
    "    df = pd.DataFrame(benchmarks)\n",
    "    df = df.reset_index()\n",
    "    sns.histplot(x='index', y=column_name, data=df)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "start_time": "2023-07-05T16:56:40.861748Z",
     "end_time": "2023-07-05T16:56:40.864807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'loss_rate'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[188], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplot_benchmarks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbenchmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mloss_rate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m benchmarks:\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Cell \u001B[1;32mIn[187], line 7\u001B[0m, in \u001B[0;36mplot_benchmarks\u001B[1;34m(benchmarks, column_name)\u001B[0m\n\u001B[0;32m      5\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(benchmarks)\n\u001B[0;32m      6\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m----> 7\u001B[0m \u001B[43msns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbarplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\categorical.py:2755\u001B[0m, in \u001B[0;36mbarplot\u001B[1;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\u001B[0m\n\u001B[0;32m   2752\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mlen\u001B[39m:\n\u001B[0;32m   2753\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 2755\u001B[0m plotter \u001B[38;5;241m=\u001B[39m \u001B[43m_BarPlotter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue_order\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2756\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrorbar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_boot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2757\u001B[0m \u001B[43m                      \u001B[49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpalette\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msaturation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2758\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrcolor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwidth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdodge\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2760\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2761\u001B[0m     ax \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mgca()\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\categorical.py:1530\u001B[0m, in \u001B[0;36m_BarPlotter.__init__\u001B[1;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001B[0m\n\u001B[0;32m   1525\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y, hue, data, order, hue_order,\n\u001B[0;32m   1526\u001B[0m              estimator, errorbar, n_boot, units, seed,\n\u001B[0;32m   1527\u001B[0m              orient, color, palette, saturation, width,\n\u001B[0;32m   1528\u001B[0m              errcolor, errwidth, capsize, dodge):\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Initialize the plotter.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1530\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestablish_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1531\u001B[0m \u001B[43m                             \u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhue_order\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43munits\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1532\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestablish_colors(color, palette, saturation)\n\u001B[0;32m   1533\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimate_statistic(estimator, errorbar, n_boot, seed)\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\categorical.py:541\u001B[0m, in \u001B[0;36m_CategoricalPlotter.establish_variables\u001B[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001B[0m\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(var, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    540\u001B[0m         err \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not interpret input \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvar\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 541\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err)\n\u001B[0;32m    543\u001B[0m \u001B[38;5;66;03m# Figure out the plotting orientation\u001B[39;00m\n\u001B[0;32m    544\u001B[0m orient \u001B[38;5;241m=\u001B[39m infer_orient(\n\u001B[0;32m    545\u001B[0m     x, y, orient, require_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequire_numeric\n\u001B[0;32m    546\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: Could not interpret input 'loss_rate'"
     ]
    }
   ],
   "source": [
    "plot_benchmarks(benchmarks, \"loss_rate\")\n",
    "for i in benchmarks:\n",
    "    print(i[\"loss_rate\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_scatter(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `test_time` for parameter `y`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[189], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplot_hist\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbenchmarks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest_time\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[187], line 17\u001B[0m, in \u001B[0;36mplot_hist\u001B[1;34m(benchmarks, column_name)\u001B[0m\n\u001B[0;32m     15\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(benchmarks)\n\u001B[0;32m     16\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m---> 17\u001B[0m \u001B[43msns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\distributions.py:1395\u001B[0m, in \u001B[0;36mhistplot\u001B[1;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001B[0m\n\u001B[0;32m   1374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhistplot\u001B[39m(\n\u001B[0;32m   1375\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   1376\u001B[0m     \u001B[38;5;66;03m# Vector variables\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1392\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   1393\u001B[0m ):\n\u001B[1;32m-> 1395\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43m_DistributionPlotter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvariables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_DistributionPlotter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_semantics\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1398\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1400\u001B[0m     p\u001B[38;5;241m.\u001B[39mmap_hue(palette\u001B[38;5;241m=\u001B[39mpalette, order\u001B[38;5;241m=\u001B[39mhue_order, norm\u001B[38;5;241m=\u001B[39mhue_norm)\n\u001B[0;32m   1402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ax \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\distributions.py:113\u001B[0m, in \u001B[0;36m_DistributionPlotter.__init__\u001B[1;34m(self, data, variables)\u001B[0m\n\u001B[0;32m    107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    109\u001B[0m     data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    110\u001B[0m     variables\u001B[38;5;241m=\u001B[39m{},\n\u001B[0;32m    111\u001B[0m ):\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvariables\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\_oldcore.py:640\u001B[0m, in \u001B[0;36mVectorPlotter.__init__\u001B[1;34m(self, data, variables)\u001B[0m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001B[39;00m\n\u001B[0;32m    636\u001B[0m \u001B[38;5;66;03m# be better handled by an internal axis information object that tracks\u001B[39;00m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001B[39;00m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;66;03m# information for numeric axes would be information about log scales.\u001B[39;00m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_var_ordered \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m}  \u001B[38;5;66;03m# alt., used DefaultDict\u001B[39;00m\n\u001B[1;32m--> 640\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massign_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvariables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    642\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m var, \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_semantic_mappings\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    643\u001B[0m \n\u001B[0;32m    644\u001B[0m     \u001B[38;5;66;03m# Create the mapping function\u001B[39;00m\n\u001B[0;32m    645\u001B[0m     map_func \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmap, plotter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\_oldcore.py:701\u001B[0m, in \u001B[0;36mVectorPlotter.assign_variables\u001B[1;34m(self, data, variables)\u001B[0m\n\u001B[0;32m    699\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_format \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlong\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 701\u001B[0m     plot_data, variables \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_assign_variables_longform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mvariables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplot_data \u001B[38;5;241m=\u001B[39m plot_data\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvariables \u001B[38;5;241m=\u001B[39m variables\n",
      "File \u001B[1;32m~\\mambaforge-pypy3\\envs\\task\\Lib\\site-packages\\seaborn\\_oldcore.py:938\u001B[0m, in \u001B[0;36mVectorPlotter._assign_variables_longform\u001B[1;34m(self, data, **kwargs)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(val, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m)):\n\u001B[0;32m    934\u001B[0m \n\u001B[0;32m    935\u001B[0m     \u001B[38;5;66;03m# This looks like a column name but we don't know what it means!\u001B[39;00m\n\u001B[0;32m    937\u001B[0m     err \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not interpret value `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` for parameter `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 938\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err)\n\u001B[0;32m    940\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    941\u001B[0m \n\u001B[0;32m    942\u001B[0m     \u001B[38;5;66;03m# Otherwise, assume the value is itself data\u001B[39;00m\n\u001B[0;32m    943\u001B[0m \n\u001B[0;32m    944\u001B[0m     \u001B[38;5;66;03m# Raise when data object is present and a vector can't matched\u001B[39;00m\n\u001B[0;32m    945\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(val, pd\u001B[38;5;241m.\u001B[39mSeries):\n",
      "\u001B[1;31mValueError\u001B[0m: Could not interpret value `test_time` for parameter `y`"
     ]
    }
   ],
   "source": [
    "plot_hist(benchmarks, \"test_time\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T16:56:41.661712Z",
     "end_time": "2023-07-05T16:56:41.685259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T16:56:41.809240Z",
     "end_time": "2023-07-05T16:56:41.846162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
